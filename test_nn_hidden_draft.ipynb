{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_nn_hidden_draft.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1uj7XO8hhG2rnoRmwg6rkew7EKm2wPUL1","authorship_tag":"ABX9TyOPZXxQnWWaUeoyHZEJrHfP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"EMYVUTX0zzGW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETWgK8rZIL54"},"source":["\n","import time\n","import numpy as np\n","import cv2\n","import scipy.special\n","import matplotlib.pyplot as plt\n","import os\n","import csv\n","\n","from os import listdir\n","from os.path import isfile, join\n","import pandas\n","from scipy import ndimage\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GF3aUW6Ck3dv"},"source":["# neural network class definition\n","class neuralNetwork :\n","\n","    # initialise the neural network\n","    def __init__(self, inputnodes, hiddennodes, outputnodes,learningrate,hiddenlayer) :\n","\n","        # set number of nodes in each input, hidden, output layer\n","        self.inodes = inputnodes\n","        self.hnodes = hiddennodes\n","        self.onodes = outputnodes\n","\n","        self.num_hiddenlayer = hiddenlayer\n","\n","        #set weight\n","        self.set_w  = []\n","        #self.w = np.random.normal(0.0, pow(self.onodes, -0.5),(self.onodes, self.inodes))\n","        self.set_w.append(np.random.normal(0.0, pow(self.inodes, -0.5),(self.hnodes, self.inodes)))\n","        for i in range(self.num_hiddenlayer-1):\n","            self.set_w.append(np.random.normal(0.0, pow(self.hnodes, -0.5),(self.hnodes, self.hnodes)))\n","        self.set_w.append(np.random.normal(0.0, pow(self.hnodes, -0.5),(self.onodes, self.hnodes)))\n","        self.set_w = np.array(self.set_w)\n","\n","        # learning rate\n","        self.lr = learningrate\n","        self.bias = []\n","        for i in range(self.num_hiddenlayer+1):\n","            self.bias.append(1)\n","        self.bias = np.array(self.bias)\n","        \n","\n","        # activation function is the sigmoid function\n","        self.activation_function = lambda x: scipy.special.expit(x)\n","        #self.derivative_function = lambda x: 1 if x>0 else 0 if x==0 else -1\n","\n","        pass\n","   \n","    \n","\n","    # train the neural network\n","    def train(self, inputs_list, targets_list) :\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","        targets = np.array(targets_list, ndmin=2).T\n","        # print('targets = ', targets)\n","\n","        result_each_layer_set = []\n","        # w_dot_input = np.dot(self.w, inputs)\n","        # outputs = self.activation_function(w_dot_input+1)\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(self.num_hiddenlayer):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","\n","        # output layer error is the (target actual)\n","        #output_errors = targets-outputs\n","        error_set = []\n","        output_errors = targets-result_each_layer_set[-1]\n","        \n","        error_set.append(output_errors)\n","        for i in range(self.num_hiddenlayer):\n","            error_set.append(np.dot(self.set_w[0-(i+1)].T,error_set[i]))\n","        \n","        # print(error_set)\n","        # print(self.set_w)\n","\n","\n","\n","        \n","        \n","        # update the weights \n","       \n","        # self.w += self.lr * np.dot((output_errors*outputs * (1.0-outputs)),np.transpose(inputs)) \n","        for i in range(len(error_set)-1):\n","            self.set_w[0-(i+1)] += self.lr * np.dot((error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)])), np.transpose(result_each_layer_set[0-(i+2)]))\n","            self.bias[0-(i+1)] +=  self.lr*self.bias[0-(i+1)] *sum(error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)]))\n","        self.set_w[0] += self.lr * np.dot((error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0])), np.transpose(inputs))\n","        self.bias[0] +=  self.lr *self.bias[0] *sum(error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0]))\n","        \n","\n","\n","        # print(\"*********\")\n","        pass\n","\n","    # query the neural network\n","    def query(self, inputs_list) :\n","\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","\n","\n","        # output = np.dot(self.w, inputs)\n","\n","        # # calculate the signals emerging \n","        # final_outputs = self.activation_function(output)\n","\n","        result_each_layer_set = []\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(self.num_hiddenlayer):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","        final_outputs = result_each_layer_set[-1]\n","\n","        return final_outputs\n","    \n","   \n","    # def write_weight(self) :\n","    #     f = open('who.txt','w',encoding='utf-8')\n","    #     f.write(str(self.who))\n","    #     f.close()\n","    #     f = open('wih.txt','w',encoding='utf-8')\n","    #     f.write(str(self.wih))\n","    #     f.close()\n","    #     print('already write!! ')\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hS0Uqe1eQAg","executionInfo":{"status":"ok","timestamp":1627844699196,"user_tz":-420,"elapsed":496,"user":{"displayName":"บริราช สินตา","photoUrl":"","userId":"12393687753832396940"}},"outputId":"d7562775-baab-4c77-eba6-d2a3a0697c5e"},"source":["\n","accuracy_each_epochs = []\n","\n","input_nodes = 5\n","output_nodes = 2\n","hidden_nodes = 3\n","\n","learning_rate = 0.1\n","hidden_layers = 1\n","\n","\n","###\n","\n","n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate,hidden_layers)\n","inputs = np.array([0.1,0.2,0.3,0.4,0.5])\n","targets = np.array([0,1])\n","\n","\n","n.train(inputs, targets)\n","n.query(inputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([[0.47833741],\n","       [0.49939036]])"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"4wc4pOu0Gg1I"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"esN8zuF5IE6A"},"source":["a = np.array([1,2,3,4,5])\n","#a = np.array([[1,2],[3,4]])\n","b = np.array([1,2])\n","# np.dot(np.transpose(a),b)\n","# np.dot(a,b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1Lo8nO780RK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627832198986,"user_tz":-420,"elapsed":525,"user":{"displayName":"บริราช สินตา","photoUrl":"","userId":"12393687753832396940"}},"outputId":"2ed18dbc-a23e-4e3f-e3bd-b1e4526e0642"},"source":["\n","a = np.array([[0.1],[0.2],[0.3]])\n","b = np.array([0.7])\n","#np.dot(np.transpose(a),b)\n","np.dot(a,b)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.07, 0.14, 0.21])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FM1SOZRpbejL","executionInfo":{"status":"ok","timestamp":1627833883816,"user_tz":-420,"elapsed":12,"user":{"displayName":"บริราช สินตา","photoUrl":"","userId":"12393687753832396940"}},"outputId":"09eab3ec-35da-43aa-d1bf-52423e7adf67"},"source":["a.T"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 3, 4, 5])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"38ShPdAipTFY"},"source":["[array([[-0.8752797 ],\n","       [ 0.12660552]]), \n"," \n"," array([[ 0.27754787],\n","       [-1.03079466],\n","       [-0.24533705]])\n"," \n"," ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsTvW-l3psPq"},"source":["[array([[-0.32843877, -0.49393965, -0.62971025, -0.3760411 , -0.13011328],\n","       [ 0.13540883,  0.577287  ,  0.17662612,  0.10087441,  0.36847161],\n","       [ 0.33135072,  0.48795237,  0.4093101 ,  0.7552548 , -0.02359004]])\n"," array([[-0.16425235, -0.16080116, -0.84859079],\n","       [ 0.1088883 , -0.57864488, -0.58643546]])]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VFovbVss9oZ"},"source":["[array([[-0.73319296],\n","       [ 0.26574069]]), \n"," \n"," \n"," array([[ 0.63166848],\n","       [-0.19391707],\n","       [-0.40134137]]),\n"," \n"," \n","  array([[-0.2196363 ],\n","       [-0.22702633],\n","       [-0.11043681],\n","       [ 0.19985197],\n","       [-0.32806212]])]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNKm15hBtCcn"},"source":["# neural network class definition\n","class neuralNetwork :\n","\n","    # initialise the neural network\n","    def __init__(self, inputnodes, hiddennodes, outputnodes,learningrate,hiddenlayer) :\n","\n","        # set number of nodes in each input, hidden, output layer\n","        self.inodes = inputnodes\n","        self.hnodes = hiddennodes\n","        self.onodes = outputnodes\n","\n","        self.num_hiddenlayer = hiddenlayer\n","\n","        #set weight\n","        self.set_w  = []\n","        #self.w = np.random.normal(0.0, pow(self.onodes, -0.5),(self.onodes, self.inodes))\n","        # self.set_w.append(np.random.normal(0.0, pow(self.inodes, -0.5),(self.hnodes, self.inodes)))\n","        # for i in range(self.num_hiddenlayer-1):\n","        #     self.set_w.append(np.random.normal(0.0, pow(self.hnodes, -0.5),(self.hnodes, self.hnodes)))\n","        # self.set_w.append(np.random.normal(0.0, pow(self.hnodes, -0.5),(self.onodes, self.hnodes)))\n","        # self.set_w = np.array(self.set_w)\n","        self.set_w.append(np.random.normal(0.0, pow(self.inodes, -0.5),(self.hnodes[0], self.inodes)))\n","        for i in range(1,len(self.hnodes)):\n","            self.set_w.append(np.random.normal(0.0, pow(self.hnodes[i-1], -0.5),(self.hnodes[i], self.hnodes[i-1])))\n","        self.set_w.append(np.random.normal(0.0, pow(self.hnodes[-1], -0.5),(self.onodes, self.hnodes[-1])))\n","        self.set_w = np.array(self.set_w)\n","\n","        # learning rate\n","        self.lr = learningrate\n","        self.bias = []\n","        for i in range(self.num_hiddenlayer+1):\n","            self.bias.append(1)\n","        self.bias = np.array(self.bias)\n","        \n","\n","        # activation function is the sigmoid function\n","        self.activation_function = lambda x: scipy.special.expit(x)\n","        #self.derivative_function = lambda x: 1 if x>0 else 0 if x==0 else -1\n","\n","        pass\n","   \n","    \n","\n","    # train the neural network\n","    def train(self, inputs_list, targets_list) :\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","        targets = np.array(targets_list, ndmin=2).T\n","        # print('targets = ', targets)\n","\n","        result_each_layer_set = []\n","        # w_dot_input = np.dot(self.w, inputs)\n","        # outputs = self.activation_function(w_dot_input+1)\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(self.num_hiddenlayer):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","\n","        # output layer error is the (target actual)\n","        #output_errors = targets-outputs\n","        error_set = []\n","        output_errors = targets-result_each_layer_set[-1]\n","        \n","        error_set.append(output_errors)\n","        for i in range(self.num_hiddenlayer):\n","            error_set.append(np.dot(self.set_w[0-(i+1)].T,error_set[i]))\n","        \n","        # print(error_set)\n","        # print(self.set_w)\n","\n","\n","\n","        \n","        \n","        # update the weights \n","       \n","        # self.w += self.lr * np.dot((output_errors*outputs * (1.0-outputs)),np.transpose(inputs)) \n","        for i in range(len(error_set)-1):\n","            self.set_w[0-(i+1)] += self.lr * np.dot((error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)])), np.transpose(result_each_layer_set[0-(i+2)]))\n","            self.bias[0-(i+1)] +=  self.lr*self.bias[0-(i+1)] *sum(error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)]))\n","        self.set_w[0] += self.lr * np.dot((error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0])), np.transpose(inputs))\n","        self.bias[0] +=  self.lr *self.bias[0] *sum(error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0]))\n","        \n","\n","\n","        # print(\"*********\")\n","        pass\n","\n","    # query the neural network\n","    def query(self, inputs_list) :\n","\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","\n","\n","        # output = np.dot(self.w, inputs)\n","\n","        # # calculate the signals emerging \n","        # final_outputs = self.activation_function(output)\n","\n","        result_each_layer_set = []\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(self.num_hiddenlayer):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","        final_outputs = result_each_layer_set[-1]\n","\n","        return final_outputs\n","    \n","   \n","    # def write_weight(self) :\n","    #     f = open('who.txt','w',encoding='utf-8')\n","    #     f.write(str(self.who))\n","    #     f.close()\n","    #     f = open('wih.txt','w',encoding='utf-8')\n","    #     f.write(str(self.wih))\n","    #     f.close()\n","    #     print('already write!! ')\n","        \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AfOu0nQYoTz"},"source":["# neural network class definition\n","class neuralNetwork :\n","\n","    # initialise the neural network\n","    def __init__(self, inputnodes, hiddennodes, outputnodes,learningrate,send_weight_state = False,weight = 0) :\n","\n","\n","        # set number of nodes in each input, hidden, output layer\n","        self.inodes = inputnodes\n","        self.hnodes = hiddennodes\n","        self.onodes = outputnodes\n","\n","        self.set_w  = []\n","        if (send_weight_state):\n","            self.set_w = weight\n","        #set weight\n","        else:\n","            #self.w = np.random.normal(0.0, pow(self.onodes, -0.5),(self.onodes, self.inodes))\n","            self.set_w.append(np.random.normal(0.0, pow(self.inodes, -0.5),(self.hnodes[0], self.inodes)))\n","            for i in range(1,len(self.hnodes)):\n","                self.set_w.append(np.random.normal(0.0, pow(self.hnodes[i-1], -0.5),(self.hnodes[i], self.hnodes[i-1])))\n","            self.set_w.append(np.random.normal(0.0, pow(self.hnodes[-1], -0.5),(self.onodes, self.hnodes[-1])))\n","        self.set_w = np.array(self.set_w)\n","\n","        # learning rate\n","        self.lr = learningrate\n","        self.bias = []\n","        for i in range(len(self.hnodes)+1):\n","            self.bias.append(1)\n","        self.bias = np.array(self.bias)\n","        \n","\n","        # activation function is the sigmoid function\n","        self.activation_function = lambda x: scipy.special.expit(x)\n","        #self.derivative_function = lambda x: 1 if x>0 else 0 if x==0 else -1\n","\n","        pass\n","   \n","    \n","\n","    # train the neural network\n","    def train(self, inputs_list, targets_list) :\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","        targets = np.array(targets_list, ndmin=2).T\n","        # print('targets = ', targets)\n","\n","        result_each_layer_set = []\n","        # w_dot_input = np.dot(self.w, inputs)\n","        # outputs = self.activation_function(w_dot_input+1)\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(len(self.hnodes)):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","\n","        # output layer error is the (target actual)\n","        #output_errors = targets-outputs\n","        error_set = []\n","        output_errors = targets-result_each_layer_set[-1]\n","        \n","        error_set.append(output_errors)\n","        for i in range(len(self.hnodes)):\n","            error_set.append(np.dot(self.set_w[0-(i+1)].T,error_set[i]))\n","        \n","        # print(error_set)\n","        # print(self.set_w)\n","\n","\n","\n","        \n","        \n","        # update the weights \n","       \n","        # self.w += self.lr * np.dot((output_errors*outputs * (1.0-outputs)),np.transpose(inputs)) \n","        for i in range(len(error_set)-1):\n","            self.set_w[0-(i+1)] += self.lr * np.dot((error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)])), np.transpose(result_each_layer_set[0-(i+2)]))\n","            self.bias[0-(i+1)] +=  self.lr*self.bias[0-(i+1)] *sum(error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)]))\n","        self.set_w[0] += self.lr * np.dot((error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0])), np.transpose(inputs))\n","        self.bias[0] +=  self.lr *self.bias[0] *sum(error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0]))\n","        \n","\n","\n","        # print(\"*********\")\n","        pass\n","\n","    # query the neural network\n","    def query(self, inputs_list) :\n","\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","\n","\n","        # output = np.dot(self.w, inputs)\n","\n","        # # calculate the signals emerging \n","        # final_outputs = self.activation_function(output)\n","\n","        result_each_layer_set = []\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(len(self.hnodes)):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","        final_outputs = result_each_layer_set[-1]\n","\n","        return final_outputs\n","    \n","   \n","    # def write_weight(self) :\n","    #     f = open('who.txt','w',encoding='utf-8')\n","    #     f.write(str(self.who))\n","    #     f.close()\n","    #     f = open('wih.txt','w',encoding='utf-8')\n","    #     f.write(str(self.wih))\n","    #     f.close()\n","    #     print('already write!! ')\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcqDXEwRs-bb"},"source":["# neural network class definition\n","class neuralNetwork :\n","\n","    # initialise the neural network\n","    def __init__(self, inputnodes, hiddennodes, outputnodes,learningrate,send_weight_state = False,weight = 0) :\n","\n","\n","        # set number of nodes in each input, hidden, output layer\n","        self.inodes = inputnodes\n","        self.hnodes = hiddennodes\n","        self.onodes = outputnodes\n","\n","        self.set_w  = []\n","        if (send_weight_state):\n","            self.set_w = weight\n","        #set weight\n","        else:\n","          #self.w = np.random.normal(0.0, pow(self.onodes, -0.5),(self.onodes, self.inodes))\n","          self.set_w.append(np.random.normal(0.0, pow(self.inodes, -0.5),(self.hnodes[0], self.inodes)))\n","          for i in range(1,len(self.hnodes)):\n","              self.set_w.append(np.random.normal(0.0, pow(self.hnodes[i-1], -0.5),(self.hnodes[i], self.hnodes[i-1])))\n","          self.set_w.append(np.random.normal(0.0, pow(self.hnodes[-1], -0.5),(self.onodes, self.hnodes[-1])))\n","          self.set_w = np.array(self.set_w)\n","\n","        # learning rate\n","        self.lr = learningrate\n","        self.bias = []\n","        for i in range(len(self.hnodes)+1):\n","            self.bias.append(1)\n","        self.bias = np.array(self.bias)\n","        \n","\n","        # activation function is the sigmoid function\n","        self.activation_function = lambda x: scipy.special.expit(x)\n","        #self.derivative_function = lambda x: 1 if x>0 else 0 if x==0 else -1\n","\n","        pass\n","   \n","    \n","\n","    # train the neural network\n","    def train(self, inputs_list, targets_list) :\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","        targets = np.array(targets_list, ndmin=2).T\n","        # print('targets = ', targets)\n","\n","        result_each_layer_set = []\n","        # w_dot_input = np.dot(self.w, inputs)\n","        # outputs = self.activation_function(w_dot_input+1)\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(len(self.hnodes)):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","\n","        # output layer error is the (target actual)\n","        #output_errors = targets-outputs\n","        error_set = []\n","        output_errors = targets-result_each_layer_set[-1]\n","        \n","        error_set.append(output_errors)\n","        for i in range(len(self.hnodes)):\n","            error_set.append(np.dot(self.set_w[0-(i+1)].T,error_set[i]))\n","        \n","        # print(error_set)\n","        # print(self.set_w)\n","\n","\n","\n","        \n","        \n","        # update the weights \n","       \n","        # self.w += self.lr * np.dot((output_errors*outputs * (1.0-outputs)),np.transpose(inputs)) \n","        for i in range(len(error_set)-1):\n","            self.set_w[0-(i+1)] += self.lr * np.dot((error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)])), np.transpose(result_each_layer_set[0-(i+2)]))\n","            self.bias[0-(i+1)] +=  self.lr*self.bias[0-(i+1)] *sum(error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)]))\n","        self.set_w[0] += self.lr * np.dot((error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0])), np.transpose(inputs))\n","        self.bias[0] +=  self.lr *self.bias[0] *sum(error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0]))\n","        \n","\n","\n","        # print(\"*********\")\n","        pass\n","\n","    # query the neural network\n","    def query(self, inputs_list) :\n","\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","\n","\n","        # output = np.dot(self.w, inputs)\n","\n","        # # calculate the signals emerging \n","        # final_outputs = self.activation_function(output)\n","\n","        result_each_layer_set = []\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(len(self.hnodes)):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","        final_outputs = result_each_layer_set[-1]\n","\n","        return final_outputs\n","    \n","   \n","    # def write_weight(self) :\n","    #     f = open('who.txt','w',encoding='utf-8')\n","    #     f.write(str(self.who))\n","    #     f.close()\n","    #     f = open('wih.txt','w',encoding='utf-8')\n","    #     f.write(str(self.wih))\n","    #     f.close()\n","    #     print('already write!! ')\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_HxQIsXs-hv"},"source":["# neural network class definition\n","class neuralNetwork :\n","\n","    # initialise the neural network\n","    def __init__(self, inputnodes, hiddennodes, outputnodes,learningrate,send_weight_state = False,weight = 0,send_bias_state = False,bias_set = 0) :\n","\n","\n","        # set number of nodes in each input, hidden, output layer\n","        self.inodes = inputnodes\n","        self.hnodes = hiddennodes\n","        self.onodes = outputnodes\n","        self.weight_each_epochs = []\n","        self.bias_each_epochs = []\n","\n","        self.set_w  = []\n","        if (send_weight_state):\n","            self.set_w = weight\n","        #set weight\n","        else:\n","            #self.w = np.random.normal(0.0, pow(self.onodes, -0.5),(self.onodes, self.inodes))\n","            self.set_w.append(np.random.normal(0.0, pow(self.inodes, -0.5),(self.hnodes[0], self.inodes)))\n","            for i in range(1,len(self.hnodes)):\n","                self.set_w.append(np.random.normal(0.0, pow(self.hnodes[i-1], -0.5),(self.hnodes[i], self.hnodes[i-1])))\n","            self.set_w.append(np.random.normal(0.0, pow(self.hnodes[-1], -0.5),(self.onodes, self.hnodes[-1])))\n","        self.set_w = np.array(self.set_w)\n","\n","        \n","        # learning rate\n","        self.lr = learningrate\n","        self.bias = []\n","        if (send_bias_state):\n","            self.bias = bias_set\n","        else:\n","            for i in range(len(self.hnodes)+1):\n","                self.bias.append(1)\n","        self.bias = np.array(self.bias)\n","        \n","\n","        # activation function is the sigmoid function\n","        self.activation_function = lambda x: scipy.special.expit(x)\n","        #self.derivative_function = lambda x: 1 if x>0 else 0 if x==0 else -1\n","\n","        pass\n","   \n","    \n","\n","    # train the neural network\n","    def train(self, inputs_list, targets_list) :\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","        targets = np.array(targets_list, ndmin=2).T\n","        # print('targets = ', targets)\n","\n","        result_each_layer_set = []\n","        # w_dot_input = np.dot(self.w, inputs)\n","        # outputs = self.activation_function(w_dot_input+1)\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(len(self.hnodes)):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","\n","        # output layer error is the (target actual)\n","        #output_errors = targets-outputs\n","        error_set = []\n","        output_errors = targets-result_each_layer_set[-1]\n","        \n","        error_set.append(output_errors)\n","        for i in range(len(self.hnodes)):\n","            error_set.append(np.dot(self.set_w[0-(i+1)].T,error_set[i]))\n","        \n","        # print(error_set)\n","        # print(self.set_w)\n","\n","\n","\n","        \n","        \n","        # update the weights \n","       \n","        # self.w += self.lr * np.dot((output_errors*outputs * (1.0-outputs)),np.transpose(inputs)) \n","        for i in range(len(error_set)-1):\n","            self.set_w[0-(i+1)] += self.lr * np.dot((error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)])), np.transpose(result_each_layer_set[0-(i+2)]))\n","            self.bias[0-(i+1)] +=  self.lr*self.bias[0-(i+1)] *sum(error_set[i] * result_each_layer_set[0-(i+1)] * (1.0 - result_each_layer_set[0-(i+1)]))\n","        self.set_w[0] += self.lr * np.dot((error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0])), np.transpose(inputs))\n","        self.bias[0] +=  self.lr *self.bias[0] *sum(error_set[-1] * result_each_layer_set[0] * (1.0 - result_each_layer_set[0]))\n","        self.weight_each_epochs.append(self.set_w.copy())\n","        self.bias_each_epochs.append(self.bias.copy())\n","\n","\n","\n","        # print(\"*********\")\n","        pass\n","\n","    # query the neural network\n","    def query(self, inputs_list) :\n","\n","        # convert inputs list to 2d array\n","        inputs = np.array(inputs_list, ndmin=2).T\n","\n","\n","        # output = np.dot(self.w, inputs)\n","\n","        # # calculate the signals emerging \n","        # final_outputs = self.activation_function(output)\n","\n","        result_each_layer_set = []\n","        result_each_layer_set.append(self.activation_function(np.dot(self.set_w[0], inputs)+self.bias[0]))\n","        for i in range(len(self.hnodes)):\n","            result_each_layer_set.append(self.activation_function(np.dot(self.set_w[i+1], result_each_layer_set[i])+self.bias[i+1]))\n","        \n","        final_outputs = result_each_layer_set[-1]\n","\n","        return final_outputs\n","    \n","   \n","    # def write_weight(self) :\n","    #     f = open('weight.txt','w',encoding='utf-8')\n","    #     # f.write(str(self.set_w))\n","    #     for i in self.set_w:\n","    #         f.write(str(i))\n","    #         f.write('/')\n","    #     f.close()\n","    #     print('already write!! ')\n","        "],"execution_count":null,"outputs":[]}]}